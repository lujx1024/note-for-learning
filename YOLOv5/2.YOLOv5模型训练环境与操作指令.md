[TOC]

# 概述

本文档记录目标检测算法`YOLOv5`的环境安装与训练注意事项

# 训练环境

## 前置环境

- NVIDIA GeForce RTX 2060
- `CUDA 11.6` `cuDNN 8.4.0`
- `Pytorch v1.13`
- `Python 3.8`

## 环境安装

1. 创建虚拟环境

   ```bash
   conda create -n gesture_yolo python=3.8 -y
   
   conda activate gesture_yolo
   ```

   > 注: 后续操作默认在已激活的虚拟环境中执行

2. 安装`Pytorch`环境

   ```bash
   pip install torch==1.13.0+cu116 torchvision==0.14.0+cu116 torchaudio==0.13.0 --extra-index-url https://download.pytorch.org/whl/cu116 
   
   # 校验安装是否成功
   python
   >>import torch
   >>torch.cuda.is_available()
   True
   ```

3. 安装`YOLOv5`环境

   ```bash
   git clone https://github.com/ultralytics/yolov5  # clone
   cd yolov5
   pip install -r requirements.txt  # install
   ```

##  数据集

`YOLOv5`训练数据集格式如下所示:

```
traning_data
|
|--train
|	|--images 
|	|--labels
|--val
|	|--images
|	|--labels
|--test
	|--images
	|--labels

```

> 注: `images`用于存放图片文件,`labels`用于存放标注文件(`xx.txt`),图片文件与标注文件一一对应，文件名相同(扩展名除外).

## 配置文件

新建配置文件,路径为`yolov5/data/gesture_v12.yaml`，内容如下:

```yaml
# Train/val/test sets as 1) dir: path/to/imgs, 2) file: path/to/imgs.txt, or 3) list: [path/to/imgs1, path/to/imgs2, ..]
path: /home/python/projects/gesture_v12_yolo  # dataset root dir
train: train/images  # train images (relative to 'path') 128 images
val: val/images  # val images (relative to 'path') 128 images
test: test/images # test images (optional)


# Classes
names:
  0: 2
  1: 4
  2: 1
  3: ok
  4: fist
  5: 5
```

## 启动训练

1. [单卡]使用预训练模型

```bash
python train.py --data gesture_v12.yaml --epochs 300 --weights yolov5l.pt  --batch-size 4
```

2. [单卡]从0开始训练

```bash
python train.py --data gesture_v12.yaml --epochs 300 --weights " " --cfg yolov5l.yaml  --batch-size 4
```

> 添加参数 `--cache ram` 或`--cache disk` 加速训练 (需要很大的 `RAM`/`disk` 空间资源).

## 可视化结果

1. 安装`tensorboard`,指令`pip install tensorboard`
2. 启动`tensorboard` 指令: `tensorboard --logdir runs\train `
3. 访问控制台: `http://localhost:6006`

## 模型校验

模型训练完成后，可使用官方模型校验脚本`val.py`进行模型校验，如下所示:

```bash
python val.py --weight runs/train/exp/weights/best.pt --data gesture_v12.yaml
```

