[TOC]

# 概述

本文档主要记录使用`Pytorch`框架训练的`YOLOv5`模型的参数量(`parameters`)和运算量(`FLOPs`).

# 参数释义

## **FLOPS**
**注意全大写**，是`Floating Point Operations per Second`的缩写，意指每秒浮点运算次数，理解为计算速度。是一个**衡量硬件性能的指标**。

## FLOPs
**注意s小写**，是`floating point operations`的缩写（`s`表复数），意指浮点运算数，理解为**计算量**。可以用来衡量算法/模型的复杂度。

## 小结

浮点运算量（FLOPs）和参数量是评估机器学习模型复杂性的两个重要指标，它们的含义和区别如下：

1. **浮点运算量 (`FLOPs`)**：FLOPs 是 `Floating Point Operations` 的缩写，代表浮点运算的次数。在机器学习中，FLOPs 通常用来衡量模型的计算复杂性或者说是模型的计算负荷。例如，一个卷积层的 `FLOPs` 可以通过以下方式计算：`卷积核的宽度 * 卷积核的高度 * 输入的通道数 * 输出的通道数 * 输出特征图的宽度 * 输出特征图的高度`。总的 `FLOPs` 是模型所有层的 `FLOPs` 之和。
2. **参数量 (`Parameters`)**：参数量代表模型中可学习参数的数量。在深度学习模型中，这通常包括所有的权重和偏置。参数量通常用来衡量模型的大小或者说是模型的存储需求。更多的参数通常意味着更复杂的模型，但也可能导致更大的过拟合风险。

这两个指标都很重要，但是它们衡量的是不同的方面。FLOPs 主要关注的是计算负担，而参数量主要关注的是存储需求和模型复杂性。在优化模型时，通常需要同时考虑这两个指标。

# 计算方法

## 参数量计算

`Pytorch`训练的模型文件通常以`.pt`扩展保存，模型参数量计算方法如下所示:

1. 加载模型。

   这可以通过使用`torch.load()` 函数来完成,

   ```python
   import torch
   model = torch.load('yolov5s.pt')['model']
   model.eval()  # 将模型设置为评估模式
   ```

   > 注意：如果模型是通过 `torch.save()` 保存的完整模型（即包含模型的结构和权重），则可以直接加载。如果保存的只是模型的参数（通过 `torch.save(model.state_dict())`），则需要先定义模型的结构，然后加载参数。

2. 查看模型的参数量

   查看模型的参数量。可以通过递归遍历模型的所有参数并累加其元素总数来完成：

   ```python
   pythonCopy codetotal_params = sum(p.numel() for p in model.parameters())
   print(f'Total number of parameters: {total_params}')
   ```

完整代码如下:

```python
import torch
import torchsummary

# weights = 'yolov5l.pt'
weights = 'weights/best.pt'

model = torch.load(weights)['model']
model.eval()  # 将模型设置为评估模式
# 查看模型的精度
# for name, parameters in model.named_parameters():
#      print(parameters.dtype) 
total_params = sum(p.numel() for p in model.parameters())
print(f'Total number of parameters: {total_params}')
```

## 运算量

要计算模型的运算量（通常以浮点运算次数（FLOPs）为单位），可以使用一些第三方库，如 `torchprofile` 或 `thop`。以下是一个使用 `thop` 的例子：

```python
from thop import profile
input = torch.randn(1, 3, 640, 640)  # 模型的输入需要根据实际情况进行修改
flops, params = profile(model, inputs=(input, ))
print(f'Total number of FLOPs: {flops}')
```

> 注：需要安装`thop`依赖，安装方法: `pip install thop`

>  注意：计算模型的运算量可能需要对模型的输入大小有具体了解。因为某些层（如卷积层）的运算量会依赖于其输入的大小。

**解决报错**:

```
Traceback (most recent call last):
  File "/home/python/projects/yolov5/model_probe.py", line 16, in <module>
    flops, params = profile(model, inputs=(input, ))
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/thop/profile.py", line 212, in profile
    model(*inputs)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/python/projects/yolov5/models/yolo.py", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/python/projects/yolov5/models/yolo.py", line 121, in _forward_once
    x = m(x)  # run
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/python/projects/yolov5/models/common.py", line 56, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: Input type (torch.FloatTensor) and weight type (torch.HalfTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor
```

根据遇到的错误提示显示，模型的权重数据类型是半精度浮点型（`torch.HalfTensor`），而提供的输入数据类型是标准的浮点型（`torch.FloatTensor`）。在进行卷积操作时，输入和权重的数据类型需要相同，或者输入应该是 MKLDNN tensor，而权重是密集 tensor。

为了解决这个问题，需要确保模型权重和输入数据的数据类型相同。在上述示例中，需要将输入数据转换为半精度浮点型。如下所示：

```python
input = torch.randn(1, 3, 640, 640).half()  # 转换为半精度浮点型
flops, params = profile(model, inputs=(input, ))
print(f'Total number of FLOPs: {flops}')
```

**解决报错**:

```
Traceback (most recent call last):
  File "/home/python/projects/yolov5/model_probe.py", line 16, in <module>
    flops, params = profile(model, inputs=(input, ))
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/thop/profile.py", line 212, in profile
    model(*inputs)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/python/projects/yolov5/models/yolo.py", line 209, in forward
    return self._forward_once(x, profile, visualize)  # single-scale inference, train
  File "/home/python/projects/yolov5/models/yolo.py", line 121, in _forward_once
    x = m(x)  # run
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1130, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/python/projects/yolov5/models/common.py", line 56, in forward
    return self.act(self.bn(self.conv(x)))
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/module.py", line 1148, in _call_impl
    result = forward_call(*input, **kwargs)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 457, in forward
    return self._conv_forward(input, self.weight, self.bias)
  File "/home/conda/envs/yolo/lib/python3.8/site-packages/torch/nn/modules/conv.py", line 453, in _conv_forward
    return F.conv2d(input, weight, bias, self.stride,
RuntimeError: "slow_conv2d_cpu" not implemented for 'Half'
```

这个错误表示`PyTorch`的 `CPU`版本不支持半精度(`half-precision`)浮点数的卷积操作。如果有可用的`GPU`，可以尝试将模型和输入数据都转移到`GPU`上，并确保它们都是**半精度**的。示例如下：

```python
model = model.cuda().half()  # 将模型转移到 GPU 上并转换为半精度
input = torch.randn(1, 3, 640, 640).cuda().half()  # 将输入数据转移到 GPU 上并转换为半精度
flops, params = profile(model, inputs=(input, ))
print(f'Total number of FLOPs: {flops}')
```

在这个例子中，`.cuda()` 方法将模型或张量转移到`GPU` 上，`.half()` 方法将其转换为**半精度**。

如果没有 GPU 或者出于某种原因不能使用 GPU，你可能需要将模型权重转换为全精度（full-precision）浮点数（`torch.FloatTensor`），然后在 CPU 上运行模型。但是这可能会增加内存使用量，并可能影响模型的表现，因为在训练过程中可能使用了半精度浮点数。

```python
model = model.float()  # 将模型转换为全精度
input = torch.randn(1, 3, 640, 640)  # 输入数据已经是全精度的
flops, params = profile(model, inputs=(input, ))
print(f'Total number of FLOPs: {flops}')
```

在这个例子中，`.float()` 方法将模型或张量转换为全精度浮点数。

完整代码如下:

```python
import torch
import torchsummary
from thop import profile

weights = 'yolov5l.pt'
# weights = 'weights/best.pt'

model = torch.load(weights)['model']
model.eval()  # 将模型设置为评估模式

#####<<< GPU 平台运行 >>>#####
# 将模型转移到 GPU 上并转换为半精度
model= model.cuda().half()
input = torch.randn(1, 3, 640, 640).cuda().half()  # 模型的输入需要根据实际情况进行修改
flops, params = profile(model, inputs=(input, ))
print(f'Total number of FLOPs: {flops} Params :{params}')
#####<<< GPU 平台运行 >>>#####

#####<<< CPU 平台运行 >>>#####
# from thop import profile
# # 将模型转换为全精度
# model= model.float()
# input = torch.randn(1, 3, 640, 640)  # 输入数据已经是全精度的
# flops, params = profile(model, inputs=(input, ))
# print(f'Total number of FLOPs: {flops} Params :{params}')
#####<<< CPU 平台运行 >>>#####
```

## 其他计算方法

`fvcore`是`Facebook`开源的一个轻量级的核心库，它提供了各种计算机视觉框架中常见且基本的功能。其中就包括了统计模型的参数以及`FLOPs`等,[开源地址](https://github.com/facebookresearch/fvcore)

1. 安装

   ```python
   pip install fvcore
   ```

2. 计算参数量和运算量

   ```python
   import torch
   from fvcore.nn import FlopCountAnalysis, parameter_count_table
   
   weights = 'yolov5l.pt'
   # weights = 'weights/best.pt'
   
   model = torch.load(weights)['model']
   # for name, parameters in model.named_parameters():
   #      print(parameters.dtype)
   model.eval()  # 将模型设置为评估模式
   model = model.float()
   input = torch.rand(1, 3, 640, 640)  # 输入数据已经是全精度的
   flops = FlopCountAnalysis(model, input)
   print("FLOPs: ", flops.total())
   print(parameter_count_table(model))
   ```

   